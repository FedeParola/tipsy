#+LaTeX_HEADER:\usepackage[margin=2cm]{geometry}
#+LaTeX_HEADER:\usepackage{enumitem}
#+LaTeX_HEADER:\usepackage{tikz}
#+LATEX:\setitemize{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt}
#+LATEX:\lstdefinelanguage{javascript}{basicstyle=\scriptsize\ttfamily,numbers=left,numberstyle=\scriptsize,stepnumber=1,showstringspaces=false,breaklines=true,frame=lines}
#+OPTIONS: toc:nil author:t ^:nil num:nil

#+TITLE: TIPSY: Telco pIPeline benchmarking SYstem
#+AUTHOR: Tamás Lévai, Felicián Németh, Gábor Rétvári (BME)

/Disclaimer: TIPSY is currently heavily work in progress!/

TIPSY is a benchmark suite to evaluate and compare the performance of
programmable data plane technologies and network-function virtualization
frameworks over a set of standard scenarios rooted in telecommunications
practice. Currently there is a BNG (Broadband Network Gateway) and a 5G MGW
(Mobile Gateway) defined and implemented in TIPSY, with further pipelines
and implementations to follow soon.

The aim of TIPSY is to provide the networking community a set of
*standardized telco-oriented scenarios* on top of which different
*programmable data plane technologies can be fairly and comprehensibly
evaluated*.  The target audience is network operators who want to test new
data-plane equipment, network engineers evaluating the scalability of a
programmable switch in terms of increasingly complex configurations, and
researchers who want to compare a new data plane algorithm with existing
and established technology.

TIPSY comprises 6 elemental parts, currently existing at varying levels of
maturity:

- a set of telco pipelines with working implementations (currently OpenFlow
  and BESS are supported, contributions are welcome),
- a test suite to validate the implementations (ongoing),
- a configuration system that allows to fine-tune general parameters of the
  pipelines (supported),
- a tunable trace generator to produce deterministic traffic traces for
  repeatable experiments and reproducible results (supported),
- a distributed measurement infrastructure to feed the traffic traces to
  the system-under-test, controller code to drive dynamic benchmarks, and
  an evaluation framework that visualizes the results (rudimentary),
- an evaluation and visualization framework to generate production-quality
  reports from the benchmark results (planned).

** What TIPSY is

- A collection of pipelines that model real telco use cases: the intention
  for TIPSY is to serve as the "de facto" data-plane benchmarking suite for
  practitioners and researchers.
- A measurement support framework: TIPSY will automatically generate
  detailed configs, working pipelines, and complete traffic traces to start
  testing right away.
- A tool to perform repeatable experiments: TIPSY devotes huge emphasis to
  support reproducibility; it automatically generates deterministic traffic
  traces, supports multiple traffic-dropping policies to never lose
  packets, etc.
- A tool to present benchmark results in a comprehensible form, like
  diagrams, charts, and tables, and a flexible way to configure and
  fine-tune these visualizations.

** What TIPSY is not

- A fully fledged measurement system: TIPSY will not setup the measurement
  configuration automatically and there are certain steps that need to be
  done manually by the user, like connecting the SUT and the tester; the
  intention is to minimize manual intervention as much as possible.
- An exhaustive collection of telco pipelines (contributions are welcome)
  or canonical implementations of the ones supported (of course, there is
  more that one way to do it).
- An Internet scale performance measurement framework: the TIPSY reference
  configuration is a single device-under-test connected back-to-back with a
  traffic generator.

** If you find TIPSY to not work for you

You can find a comprehensive list of alternative data plane benchmark
suites and lots of background on data plane testing in the below paper.

Matthias Holdorf,
[[https://www.net.in.tum.de/fileadmin/TUM/NET/NET-2016-07-1/NET-2016-07-1_05.pdf][How-To Compare Performance of Data Plane Devices]],
Proceedings of the Seminars Future Internet (FI) and Innovative Internet
Technologies and Mobile Communications (IITM), 2016.

* Architecture

The general TIPSY setup will contain a System-Under-Test (SUT) that runs
the data plane to be evaluated, a Tester that feeds the SUT with a traffic
trace and measures performance, and a Controller that sets up the static
pipeline and, optionally, exercises the performance of the SUT under
updates.  Drawing from telco practice, TIPSY distinguishes between the
*uplink* direction (user-to-network direction) and the *downlink* direction
(network-to-user direction); the downlink port is the attachment port for
the access network (users) and the uplink port connects to the public
Internet. In pratice, however, the uplink and downlink ports of the SUT are
connected back-to-back to the same Tester device for supporting versatile
evaluation setups.

:                                  +---------------------+
:                                  |                     |
:                                  |    *Controller*     |
:                                  |                     |
:                                  +---------------------+
:                                             A
:                                             |
:                                             V
:   +----------------+             +---------------------+
:   |                |             |                     |
:   |     uplink_port|<----------->|downlink_port        |
:   |                |             |                     |
:   |                |             |                     |
:   |    *Tester*    |             | *System Under Test* |
:   |                |             |        (SUT)        |
:   |                |             |                     |
:   |                |             |                     |
:   |   downlink_port|<----------->|uplink_port          |
:   |                |             |                     |
:   +----------------+             +---------------------+

Apart from static pipeline configurations, aimed for evaluating the SUT in
steady state, TIPSY also contains additional scenarios to benchmark the SUT
in dynamic workloads, i.e., when the control plane updates the data plane
program at various (and configurable) intensities.  The implementations
that come with TIPSY pipelines contain code to feed the updates, via the
Controller module, into the SUT.

* Pipelines

The below table provides an overview of TIPSY pipelines along with the
features each one uses and the current availability of an implementation in
the TIPSY code.

#+ATTR_LaTeX: :align |c|c|c|c|c|c|c|c|c|c|
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
|                                                        | Encap/Decap | ParseField | SetField | RateLimit | Firewall | NAT | Status |
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| PORTfwd                                                | -           | -          | -        | -         | -        | -   | TODO   |
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| L2fwd                                                  | -           | L2         | -        | -         | -        | -   | TODO   |
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| L3fwd                                                  | -           | L2/L3      | L2/L3    | -         | -        | -   | TODO   |
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| Encap/Decap                                            | VXLAN       | -          | L2/L3    | -         | -        | -   | TODO   |
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| RateLimit                                              | -           | -          | -        | x         | -        | -   | TODO   |
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| Firewall                                               | -           | L2/L3/L4   | -        | -         | x        | -   | TODO   |
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| NAT                                                    | -           | L2/L3/L4   | L2/L3/L4 | -         | -        | x   | TODO   |
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| Data Center GW (DCGW)                                  | VXLAN       | L2/L3      | L2/L3    | -         | -        | x   | TODO   |
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| [[././doc/README.mgw.org][Mobile GW (MGW)]]            | GTP         | L2/L3/L4   | L2/L3    | x         | -        | -   | OK     |
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| [[././doc/README.bng.org][Broadband Network GW (BNG)]] | GRE         | L2/L3/L4   | L2/L3    | x         | x        | x   | OK     |
|--------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|

* Installation and usage

** Installation

TIPSY does not require explicit installation but the =tipsy= executable
must always be available and executable; the easiest setup is to add the
tipsy root directory to the PATH.

#+BEGIN_SRC sh
$ git clone https://github.com/hsnlab/tipsy
$ cd tipsy
$ export PATH=$PWD:$PATH
<run benchmarks>
#+END_SRC

** High-level configuration

Input to TIPSY is a high-level description of the intended measurement,
like the name of the pipeline to be coded into the SUT and the general
parameters (number of users, number of Internet routes, etc.) and the
output is a set of configurations/data-plane programs that can be loaded
into the SUT and a set of traffic traces for each config.  Currently these
must be loaded manually into the SUT and the Tester; fully automated
benchmarking is a work-in-progress at the moment.

#+BEGIN_SRC javascript
{
    "benchmark":
    [
        {
	    "id": "my_benchmark",
            "scale": "joint",
            "pipeline": {
                "name": "mgw",
                "param1": [1,2],
                "param2": [5,10],
                "param3": false,
                <various pipeline specific parameters>
            }
        },
    ]
}
#+END_SRC

The high-level configuration defines a set of benchmarks to be evaluated in
a single JSON file. The parameters describe way the benchmarks are to be
evaluated.

The =scale= parameter describes the way the individual benchmarks in the
scalability test to be executed.
- =scale=: perform scalability tests by repeating the benchmark multiple
  times, each time setting one or all parameters as specified in the =args=
  - =none=: do not perform scalability tests (default)
  - =outer=: take the outer product of the argument lists and generate a
    separate benchmark for all combinations
  - =joint=: scale the parameters jointly

In the above example, for instance, the benchmark sets =scale= to =outer=,
which means that a separate benchmark will be tun for each combination of
list of values given for the pipeline specific parameters =param1=,
=param2=, =param3=.  Correspondingly, the first benchmark will have
=param1=, =param2=, and =param3= set to =[1,5,false]=, the second to
=[2,5,false]=, the third to =[1,10,false]=, etc.  If =scale= is set to
=jointall=, on the other hand, then the parameters will be scaled jointly
by first taking the first setting in the list for each param, then the
second, etc., i.e., =param1=, =param2=, and =param3= set first to
=[1,5,false]= and then to =[2,10,false]=. Setting =scale= to =none= ignores
parameter lists and generates a single benchmark for the first scalar for
each argument.

For the pipeline specific parameters, see the documentation for each
pipeline.

** TODO Run TIPSY

The first step to run each benchmark is to create a new benchmark root
directory, which will contain all files (configuration, traffic trace, data
plane config, results, etc.) associated with the benchmark, and creating a
high-level JSON configuration for the benchmark.  Then, to actually run the
benchmark simply issue the necessary TIPSY commands through running the
benchmark driver executable =tipsy= in the benchmark root directory with
different command line arguments.

#+BEGIN_SRC sh
mkdir my_bng_benchmark
cd my_bng_benchmark
<store a TIPSY benchnmark configuration into a JSON file>
tipsy config 
tipsy traffic-gen
tipsy run
...
tipsy clean
#+END_SRC

The basic workflow is as follows.

1. Create the benchmark root directory as above.

   #+BEGIN_SRC sh
   mkdir my_bng_benchmark
   cd my_bng_benchmark
   #+END_SRC

2. Place a main TIPSY configuration file =my_benchmark.json= into the root
   directory and edit it according to your needs. The below configuration
   will set up the =MGW= pipeline and benchmark the OVS and the BESS
   backends, while scaling the number of users from 10 to 1000.

   #+BEGIN_SRC javascript
     {
         "benchmark": {
             "id": "test1"
             "scale": "outer",
             "pipeline": {
                 "name": "mgw",
                 "user": [10, 100, 1000, 1000],
             }
         },
         "traffic": {
             "pkt-size": 64,
         },
         "sut": {
             "type": ["ovs", "bess"]
         },
         "visualize":
         [
             {
                 "x_axis": "mgw.user", 
                 "y_axis": "packet_rate",
                 "curve": ["ovs", "bess"]
             }
         ]
     }
   #+END_SRC

3. Generate the configuration for the individual test cases that make up
   the benchmark, that is, a separate test for all settings of the =user=
   and =backend= parameters, with each test case configuration placed into
   a separate directory.

   #+BEGIN_SRC sh
   tipsy config my_benchmark.json
   #+END_SRC

   This call will set the benchmark configuration from =my_benchmark.json=,
   setting each parameter that was not explicitly specified there to a sane
   default value.

   You may also omit the JSON files from the command line in which case
   TIPSY will take the first JSON file it finds in the current directory as
   a configuration for the benchmark (the same applies to the subsequent
   =tipsy= invocations).

   #+BEGIN_SRC sh
   tipsy config
   #+END_SRC

4. Generate the sample traffic traces that will be fed to the SUT during
   the benchmark (this may take a while).

   #+BEGIN_SRC sh
   tipsy traffic-gen
   #+END_SRC

5. Run the benchmark (this may take an even longer while).

   #+BEGIN_SRC sh
   tipsy run
   #+END_SRC

6. Evaluate, and visualize: these features have not been implemented yet so
   you must do these manually by now.

There is a TIPSY design document available
[[./doc/README.vision.org][here]] that describes how we imagine an ideal
TIPSY workload when all missing pieces will eventually have fallen into
place.

** Until we get there

At the moment the =tipsy= benchmark driver executable is still
work-in-progress and some commands may not work perfectly reliably.  The
below examples will help you leveraging the valuable and finished parts of
TIPSY until it gets into a production-ready state.

#+BEGIN_SRC sh
$ ./gen/gen-conf.py --pipeline bng --user 10 > ryu/conf.json
$ cd ryu
$ ryu-manager --config-dir .
#+END_SRC

The above code generates a config for the BNG pipeline with setting the
number of users to 10 and using the default settings otherwise and then
runs the =Ryu= controller to set up the pipeline in OpenFlow (note that an
OpenFlow switch, like Open vSwtich, needs to be started separately).

Another example:
#+BEGIN_SRC sh
$ ./gen/gen-conf.py --pipeline mgw --handover 2 > conf.json
$ ./bess/update-agent.py -d /path/to/bess -c conf.json
#+END_SRC

This snippet generates an MGW pipeline and runs the pipeline in BESS. Note
that the code automatically starts BESS.


* Miscellaneous

You can make the output a bit more readable by installing
=ryu/color_log.py=, read the header of =ryu/color_log.py= for how to do
that.

* TODO License

