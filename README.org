#+LaTeX_HEADER:\usepackage[margin=2cm]{geometry}
#+LaTeX_HEADER:\usepackage{enumitem}
#+LaTeX_HEADER:\usepackage{tikz}
#+LATEX:\setitemize{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt}
#+LATEX:\lstdefinelanguage{javascript}{basicstyle=\scriptsize\ttfamily,numbers=left,numberstyle=\scriptsize,stepnumber=1,showstringspaces=false,breaklines=true,frame=lines}
#+OPTIONS: toc:nil ^:nil num:nil

#+TITLE: TIPSY: Telco pIPeline benchmarking SYstem

/Disclaimer: TIPSY is currently heavily work in progress!/

TIPSY is a benchmark suite to evaluate and compare the performance of
programmable data plane technologies and network-function virtualization
frameworks over a set of standard scenarios rooted in telecommunications
practice. Apart from simple L2 and L3 pipelines, currently there is a
rather complex BNG (Broadband Network Gateway) and 5G MGW (Mobile Gateway)
pipeline defined and implemented in TIPSY, with further pipelines and
implementations to follow soon.

The aim of TIPSY is to provide the networking community a set of
*standardized telco-oriented scenarios* on top of which different
*programmable data plane technologies can be fairly and comprehensibly
evaluated*.  The target audience is network operators who want to test new
data-plane equipment, network engineers evaluating the scalability of a
programmable switch in terms of increasingly complex configurations, or
researchers who want to compare a new data plane algorithm with existing
and established technology.

TIPSY comprises 6 elemental parts, currently existing at varying levels of
maturity:

- a set of telco pipelines with working implementations (currently OpenFlow
  and BESS are supported, contributions are welcome),
- a test suite to validate the implementations (ongoing),
- a configuration system that allows to fine-tune general parameters of the
  pipelines (supported),
- a tunable trace generator to produce deterministic traffic traces for
  repeatable experiments and reproducible results (supported),
- a distributed measurement infrastructure to feed the traffic traces to
  the system-under-test, controller code to drive dynamic benchmarks, and
  an evaluation framework that visualizes the results (rudimentary),
- an evaluation and visualization framework to generate production-quality
  reports from the benchmark results (planned).

** What TIPSY is

- A collection of pipelines that model real telco use cases: the intention
  for TIPSY is to serve as the "de facto" data-plane benchmarking suite for
  practitioners and researchers.
- A measurement support framework: TIPSY will automatically generate
  detailed configs, working pipelines, and complete traffic traces to start
  testing right away.
- A tool to perform repeatable experiments: TIPSY devotes huge emphasis to
  support reproducibility; it automatically generates deterministic traffic
  traces, supports multiple traffic-dropping policies to never lose
  packets, etc.
- A tool to present benchmark results in a comprehensible form, like
  diagrams, charts, and tables, and a flexible way to configure and
  fine-tune these visualizations (TODO).

** What TIPSY is not

- A standalone automatic measurement system: TIPSY will never be able to
  setup the measurement completely unattended and there are certain steps,
  like connecting the SUT and the tester, that will need to be done
  manually anyway; the intention is to minimize manual intervention as much
  as possible.
- An exhaustive collection of telco pipelines (contributions are welcome)
  or canonical implementations of the ones supported (of course, there is
  more that one way to do it).
- An Internet scale performance measurement framework: the TIPSY reference
  configuration is a single device-under-test connected back-to-back to a
  traffic generator/measurement device; benchmarking multi-hop setups or
  complex network topologies are out of scope for TIPSY.

** If you find TIPSY to not work for you

You can find a comprehensive list of alternative data plane benchmark
suites and lots of background on data plane testing in the below paper.

Matthias Holdorf,
[[https://www.net.in.tum.de/fileadmin/TUM/NET/NET-2016-07-1/NET-2016-07-1_05.pdf][How-To Compare Performance of Data Plane Devices]],
Proceedings of the Seminars Future Internet (FI) and Innovative Internet
Technologies and Mobile Communications (IITM), 2016.

* Architecture

The general TIPSY setup will contain a System-Under-Test (SUT) that runs
the data plane to be evaluated, a Tester that feeds the SUT with a traffic
trace and measures performance, and a Controller running on the SUT that
sets up the static pipeline and, optionally, exercises the performance of
the SUT under updates.  Drawing from telco practice, TIPSY distinguishes
between the *uplink* direction (user-to-network direction) and the
*downlink* direction (network-to-user direction); the downlink port is the
attachment port for the access network (users) and the uplink port connects
to the public Internet. In pratice, however, the uplink and downlink ports
of the SUT are connected back-to-back to the same Tester device. A
management access is also required between the two to let the Tester
configure the SUT via Secure Shell.

:   +----------------+             +---------------------+
:   |                |             |                     |
:   |                |             |                     |
:   |     uplink_port|<----------->|downlink_port        |
:   |                |             |                     |
:   |                |             |                     |
:   |    *Tester*    |             | *System Under Test* |
:   |                |             |        (SUT)        |
:   |                |             |          +          |
:   |                |             |     *Controller*    |
:   |                |             |                     |
:   |                |             |                     |
:   |   downlink_port|<----------->|uplink_port          |
:   |                |             |                     |
:   |                |             |                     |
:   |                |<---mgmt---->|                     |
:   +----------------+             +---------------------+

Apart from static pipeline configurations, aimed for evaluating the SUT in
steady state, TIPSY also contains additional scenarios to benchmark the SUT
in dynamic workloads, i.e., when the control plane updates the data plane
program at various (and configurable) intensities.  The implementations
that come with TIPSY pipelines contain code to feed the updates, via the
Controller module, into the SUT.

* Pipelines

The below table provides an overview of TIPSY pipelines along with the
features each one uses and the current availability of an implementation in
the TIPSY code.

#+ATTR_LaTeX: :align |c|c|c|c|c|c|c|c|c|c|
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
|                                                      | Encap/Decap | ParseField | SetField | RateLimit | Firewall | NAT | Backends |
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| [[./doc/README.portfwd.org][Port forward (PORTfwd)]] | -           | -          | -        | -         | -        | -   | ovs, bess |
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| [[./doc/README.L2fwd.org][L2 forward (L2fwd)]]       | -           | L2         | -        | -         | -        | -   | ovs, bess |
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| [[./doc/README.L3fwd.org][L3 forward (L3fwd)]]       | -           | L2/L3      | L2/L3    | -         | -        | -   | ovs, bess   |
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| Encap/Decap                                          | VXLAN       | -          | L2/L3    | -         | -        | -   |        |
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| RateLimit                                            | -           | -          | -        | x         | -        | -   |        |
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| Firewall                                             | -           | L2/L3/L4   | -        | -         | x        | -   |        |
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| NAT                                                  | -           | L2/L3/L4   | L2/L3/L4 | -         | -        | x   |        |
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| Data Center GW (DCGW)                                | VXLAN       | L2/L3      | L2/L3    | -         | -        | x   |        |
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| [[./doc/README.mgw.org][Mobile GW (MGW)]]            | GTP         | L2/L3/L4   | L2/L3    | x         | -        | -   | ovs, bess |
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|
| [[./doc/README.bng.org][Broadband Network GW (BNG)]] | GRE         | L2/L3/L4   | L2/L3    | x         | x        | x   | ovs      |
|------------------------------------------------------+-------------+------------+----------+-----------+----------+-----+--------|

* Installation and usage

** Installation
TIPSY depends on external software components. To run TIPSY, it is
necessary to install the following:

On SUT:
- sudo,
- screen.

On Tester:
- ssh,
- python-jsonschema,
- scapy.

TIPSY does not require explicit installation but the =tipsy= executable
must always be available and executable; the easiest setup is to add the
TIPSY main directory to the PATH.

#+BEGIN_SRC sh
git clone https://github.com/hsnlab/tipsy
cd tipsy
export PATH=$PWD:$PATH
#+END_SRC

** Main TIPSY benchmark configuration

Input to TIPSY is a high-level description of the intended measurement,
like the name of the pipeline to be coded into the SUT and the general
parameters (number of users, number of Internet routes, etc.) and the
output is a set of configurations/data-plane programs that can be loaded
into the SUT and a set of traffic traces for each config.

Below is a sample configuration that defines a benchmark on the
[[./doc/README.mgw.org][Mobile Gateway (MGW)]] (=mgw=) pipeline, with
pipeline-specific settings =user= (number of users) and =bst= (number of
base stations) as set in the =pipeline= section.

#+BEGIN_SRC javascript
{
    "benchmark":
    [
        {
	    "id": "my_benchmark",
            "scale": "joint",
            "pipeline": {
                "name": "mgw",
                "user": [1,2],
                "bst": [5,10],
            }
        }
    ]
}
#+END_SRC

The =id= parameter sets a name for the benchmark and =scale= describes the
way the individual benchmark instances in the scalability benchmark are to
be executed. TIPSY allows to easily request and perform scalability tests
by repeating the benchmark multiple times, each time setting one or all
parameters as controlled by the =scale= setting:
- =none=: do not perform scalability tests (default),
- =outer=: take the outer product of all settings specified for the
  benchmark and generate a separate test case for all,
- =joint=: scale the parameters jointly.

In the above example =scale= is set to =joint=, which tells TIPSY to scale
the parameters specified as /lists/ in the config (=user= and =bst=)
jointly, that is, take the first setting in the list for each parameter,
then the second, etc., and generate a test for each such tuple.  In the
above example, this will result in two tests to be run, one when =user= is
set to 1 and =bst= is set to 5 (the first elements of the lists), and one
when =user= is set to 2 and =bst= is 10 (the second elements of the lists).

If =scale= is set to =outer=, then a separate test will be run for each
combination of the multi-valued settings (=user= and =bst=), i.e., we get 4
tests, first setting the (=user=, =bst=) tuple to (1,5), then to (1,10),
then to (2,5), and finally to (2,10).

Setting =scale= to =none= ignores parameter lists and generates a single
benchmark for the first scalar for each argument.

A detailed TIPSY configuration guide can be found
[[./doc/README.config.org][here]].  For the pipeline specific parameters,
see the documentation for each pipeline. For generating an empty
configuration with the default setting for each configurable parameter,
use:

#+BEGIN_SRC sh
tipsy init <pipeline>
#+END_SRC

You may then start to edit the resultant JSON configuration accordingly.

** TODO Run TIPSY

The first step to run a benchmark is to create a root directory that will
contain all files (configurations, traffic traces, data plane configs,
results, etc.) associated with the benchmark and to write the main JSON
configuration.  Then, to actually run the benchmark, simply issue the
necessary TIPSY commands executing the benchmark driver =tipsy= in the
benchmark root directory with different command line arguments.

#+BEGIN_SRC sh
mkdir my_benchmark
cd my_benchmark
<store a TIPSY benchnmark configuration into a JSON file>
tipsy config
tipsy traffic-gen
tipsy run
...
tipsy clean
#+END_SRC

The basic workflow is as follows.

1. Create the benchmark root directory as above.

   #+BEGIN_SRC sh
   mkdir my_benchmark
   cd my_benchmark
   #+END_SRC

2. Place a main TIPSY configuration file =my_benchmark.json= into the root
   directory and edit it according to your needs. The below configuration
   will set up the [[././doc/README.mgw.org][Mobile Gateway (MGW)]] (=mgw=)
   pipeline and benchmark the OVS and the BESS backends, while scaling the
   number of users from 10 to 1000.

   #+BEGIN_SRC javascript
{
    "benchmark": [
        {
            "id": "my_benchmark",
            "scale": "outer",
            "pipeline": {
                "name": "mgw",
                "user": [1, 10, 100, 1000]
            },
            "traffic": {
                "pkt-num": 10000,
                "pkt-size": [64, 128]
            }
        }
    ],
    "environment": {
        "sut": {
            "type": ["ovs", "bess],
        },
        "tester": {
            "type": "moongen",
            "test-time": 30
        }
    },
    "visualize": []
}
   #+END_SRC

   See the detailed TIPSY configuration guide
   [[./doc/README.config.org][here]].

3. Generate the configuration for the individual test cases that make up
   the benchmark, that is, a separate test for all settings of the =user=
   and =backend= parameters, with each test case configuration placed into
   a separate directory.

   #+BEGIN_SRC sh
   tipsy config my_benchmark.json
   #+END_SRC

   This call will create the benchmark configuration from
   =my_benchmark.json=, setting each parameter that was not explicitly
   specified there to a sane default value.

   You may also omit the file argument from =tipsy config= in which case
   TIPSY will take the first JSON file it finds in the current directory as
   a configuration for the benchmark.  The same applies to all =tipsy=
   invocations.

   #+BEGIN_SRC sh
   tipsy config
   #+END_SRC

4. Generate the sample traffic traces that will be fed to the SUT during
   the benchmark (this may take a while).

   #+BEGIN_SRC sh
   tipsy traffic-gen
   #+END_SRC

5. Run the benchmark (this may take an even longer while).

   #+BEGIN_SRC sh
   tipsy run
   #+END_SRC

   Currently, the remote configuration system is fairly rudimentary, like
   you must specify SSH passwords as clear text in the JSON config, etc.,
   finalizing this step is currently a main TODO item for TIPSY.

6. Evaluate, and visualize: these features have not been implemented yet so
   you must do these manually by now.

7. Clean up the benchmark directory by removing all temporary files (pcaps,
   logs, etc.) but leave the results untouched.

   #+BEGIN_SRC sh
   tipsy clean
   #+END_SRC

There is a TIPSY design document available
[[./doc/README.vision.org][here]] that summarizes a hypothetical TIPSY
session once all missing pieces will eventually have fallen into their
place.

** Until we get there

At the moment the =tipsy= benchmark driver executable is still
work-in-progress and some commands may not work perfectly reliably.  The
below examples will help you leveraging the valuable and finished parts of
TIPSY until it gets into a production-ready state.

#+BEGIN_SRC sh
cd <TIPSY_DIR>
./gen/gen-conf.py --pipeline bng --user 10 > ryu/conf.json
cd ryu
ryu-manager --config-dir .
#+END_SRC

The above code generates a config for the BNG pipeline with setting the
number of users to 10 and using the default settings otherwise and then
runs the =Ryu= controller to set up the pipeline in OpenFlow (note that an
OpenFlow switch, like Open vSwtich, needs to be started separately).

Another example:
#+BEGIN_SRC sh
cd <TIPSY_DIR>
./gen/gen-conf.py --pipeline mgw --handover 2 > conf.json
./bess/update-agent.py -d /path/to/bess -c conf.json
#+END_SRC

This snippet generates an MGW pipeline and runs the pipeline in BESS. Note
that the code automatically starts BESS.

* Miscellaneous

You can make the output a bit more readable by installing
=ryu/color_log.py=, read the header of =ryu/color_log.py= for how to do
that.

* License

TIPSY is a free software and licensed under [[./LICENSE][GPLv3+]].
